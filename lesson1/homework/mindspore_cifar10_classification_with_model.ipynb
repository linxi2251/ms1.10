{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 初级实践培训作业：CIFAR10图像分类\n",
    "\n",
    "本任务基于MindSpore的API来实现LeNet模型，并使用高阶封装`Model`进行模型训练、评估和推理。\n",
    "\n",
    "本次任务中共有处代码缺失，请根据提示补齐代码，保证代码跑通，模型完成训练及评估。\n",
    "\n",
    "## 作业提交\n",
    "\n",
    "请将补充好代码并保存运行结果的notebook，提交至大模型平台，并填写调查问卷进行登记。调查问卷链接：[Link](https://wj.qq.com/s2/13864952/l0qz/)\n",
    "\n",
    "大模型平台作业提交指南会通过邮件和本脚本发送，学员也可再微信交流群中查收作业提交视频指南。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 环境准备\n",
    "\n",
    "1. 安装MindSpore 1.10\n",
    "\n",
    "    请参考[此链接](https://gitee.com/mindspore/docs/tree/r1.10/install)，选择对应硬件的安装指南。\n",
    "\n",
    "    如：希望在windows CPU上安装MindSpore，建议点击mindspore_cpu_win_install_pip.md查看安装指南\n",
    "\n",
    "2. 安装download\n",
    "\n",
    "    `pip install download`\n",
    "    \n",
    "3. 安装matplotlib\n",
    "\n",
    "    `pip install matplotlib`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-17T08:29:16.026329264Z",
     "start_time": "2023-12-17T08:29:14.547724189Z"
    }
   },
   "outputs": [],
   "source": [
    "import mindspore\n",
    "from mindspore import nn\n",
    "from mindspore import dtype as mstype\n",
    "from mindspore.common.initializer import Normal\n",
    "from mindspore.dataset import Cifar10Dataset, vision, transforms\n",
    "from mindspore.train import Model, CheckpointConfig, ModelCheckpoint, LossMonitor\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 下载并处理数据集\n",
    "\n",
    "### 数据集加载\n",
    "\n",
    "CIFAR-10数据集共有60000张32*32的彩色图像，分为10个类别，每类有6000张图，数据集一共有50000张训练图片和10000张评估图片。\n",
    "\n",
    "首先，使用`download`库下载CIFAR10数据集并解压，后使用`mindspore.dataset.Cifar10Dataset`加载数据集。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://mindspore-website.obs.cn-north-4.myhuaweicloud.com/notebook/datasets/cifar-10-binary.tar.gz (162.2 MB)\n",
      "\n",
      "file_sizes: 100%|████████████████████████████| 170M/170M [00:15<00:00, 11.2MB/s]\n",
      "Extracting tar.gz file...\n",
      "Successfully downloaded / unzipped to ./data\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# Download data from open datasets\n",
    "from download import download\n",
    "\n",
    "url = \"https://mindspore-website.obs.cn-north-4.myhuaweicloud.com/notebook/datasets/cifar-10-binary.tar.gz\"\n",
    "path = download(url, \"./data\", kind=\"tar.gz\", replace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 数据集处理\n",
    "\n",
    "通常情况下，我们需要对数据进行数据增强，从而增强模型的泛化性。在对Cifar10数据集的处理中，我们进行了如下操作：\n",
    "\n",
    "- 仅针对训练数据集\n",
    "    - 对图像数据进行随机裁剪（已实现）\n",
    "    - 对图像数据进行随机水平翻转（已实现）\n",
    "- 针对训练数据集和测试数据集\n",
    "    - 使用`vision.Resize`，将图片数据的大小变为32x32\n",
    "    - 使用`vision.Rescale`，将图片数据的元素数值缩小为原本的1/255\n",
    "    - 使用`vision.Normalize`将图片数据进行归一化（已实现）\n",
    "    - 使用`vision.HWC2CHW`将图片数据的shape从(height, width, channel)变为(channel, height, width)\n",
    "    - 使用`transforms.TypeCast`将标签数据类型转换为`mindspore.Int32`(已实现)\n",
    "- 将如上数据变换通过`map`分别添加到图片数据和标签数据中\n",
    "- 使用`batch`对数据集进行批处理\n",
    "\n",
    "***练习一：请根据上述说明，补充数据预处理代码***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-17T08:37:54.092668025Z",
     "start_time": "2023-12-17T08:37:54.050596890Z"
    }
   },
   "outputs": [],
   "source": [
    "def datapipe(data_path, usage, resize, batch_size):\n",
    "    \"\"\"数据处理Pipeline\n",
    "\n",
    "    Args:\n",
    "        data_path: 数据集路径\n",
    "        usage: 训练数据集或测试数据集，输入为'train'或者'test'\n",
    "        resize: 图像输出尺寸大小\n",
    "        batch_size: batch大小\n",
    "    \"\"\"\n",
    "\n",
    "    # 加载数据集\n",
    "    dataset = Cifar10Dataset(data_path, usage)\n",
    "\n",
    "    # 图像数据变换\n",
    "    image_trans = []\n",
    "\n",
    "    if usage == \"train\":\n",
    "        image_trans += [\n",
    "            vision.RandomCrop((32, 32), (4, 4, 4, 4)),  # 随机裁剪\n",
    "            vision.RandomHorizontalFlip(prob=0.5)  # 随机水平翻转\n",
    "        ]\n",
    "\n",
    "    image_trans += [\n",
    "        # 练习一：请在此处补充Resize和Rescale代码\n",
    "        vision.Resize((32, 32)),\n",
    "        vision.Rescale(1.0 / 255.0, 0.0),\n",
    "        vision.Normalize([0.4914, 0.4822, 0.4465], [0.2023, 0.1994, 0.2010]),  # 归一化\n",
    "        # 练习一：请在此处补充输入图像shape的转换代码\n",
    "        vision.HWC2CHW()\n",
    "\n",
    "    ]\n",
    "\n",
    "    # 标签数据数据变换\n",
    "    label_trans = transforms.TypeCast(mstype.int32)\n",
    "\n",
    "    # 练习一：请在此处补充数据映射操作代码\n",
    "    # 提示：数据集每列的名称，可以通过dataset.get_col_names()获取\n",
    "    image, label = dataset.get_col_names()\n",
    "    dataset = dataset.map(image_trans, image)\n",
    "    dataset = dataset.map(label_trans, label)\n",
    "    \n",
    "    # 练习一：请在此处补充批量操作代码\n",
    "    dataset = dataset.batch(batch_size, drop_remainder=True)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***练习二：请使用`create_tuple_iterator`或`create_dict_iterator`，获取图像数据的shape。***\n",
    "\n",
    "图像数据的shape应该是(batch_size, channel, height, width)格式，其中batch_size为批的大小，channel为通道数，height和width是设定的resize后输出图片大小尺寸。\n",
    "\n",
    "注：Tensor的shape可以通过`Tensor.shape`获取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 3, 32, 32)\n",
      "(64,)\n"
     ]
    }
   ],
   "source": [
    "train_dataset = datapipe(os.path.join(path, 'cifar-10-batches-bin'), 'train', 32, 64)\n",
    "test_dataset = datapipe(os.path.join(path, 'cifar-10-batches-bin'), 'test', 32, 64)\n",
    "\n",
    "# 练习二：请打印出任意数据集中图像数据的shape\n",
    "image, label = next(train_dataset.create_tuple_iterator())\n",
    "print(image.shape)\n",
    "print(label.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 创建模型\n",
    "\n",
    "本次练习中，将使用LetNet5模型进行图像分类，LetNet5的模型结构如下图所示：\n",
    "\n",
    "![lenet5](https://bkimg.cdn.bcebos.com/pic/30adcbef76094b36acaf1cb689986bd98d1001e93716?x-bce-process=image/watermark,image_d2F0ZXIvYmFpa2U5Mg==,g_7,xp_5,yp_5/format,f_auto)\n",
    "\n",
    "结构拆解为：\n",
    "1. 卷积神经网络(`nn.Conv2d`)：输出channel数为6，卷积核大小为5x5，stride为1\n",
    "2. 激活函数ReLU(`nn.ReLU`)\n",
    "3. 最大池化层(`nn.MaxPool2d`)：池化核大小为2，stride为2\n",
    "4. 卷积神经网络(`nn.Conv2d`)：输出channel数为16，卷积核大小为5x5，stride为1\n",
    "5. 激活函数ReLU(`nn.ReLU`)\n",
    "6. 最大池化层(`nn.MaxPool2d`)：池化核大小为2，stride为2\n",
    "7. 使用`nn.Flatten`对输入第0维以外的维度进行展平操作\n",
    "8. 全连接层(`nn.Dense`)：输出维度为120\n",
    "9. 激活函数ReLU(`nn.ReLU`)\n",
    "10. 全连接层(`nn.Dense`)：输出维度为84\n",
    "11. 激活函数ReLU(`nn.ReLU`)\n",
    "12. 全连接层(`nn.Dense`)：输出维度为分类数量\n",
    "\n",
    "***练习三：请参考上述模型结构，补齐模型构建的代码。***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNet5(nn.Cell):\n",
    "\n",
    "    def __init__(self, num_class, num_channel):\n",
    "        super(LeNet5, self).__init__()\n",
    "        # 练习三：实例化神经网络层，设置状态；第一个卷积神经网络已给出示例\n",
    "        # nn.Conv2d(in_channels=?, out_channels=?, kernel_size=?, stride=?, pad_mode='valid')\n",
    "        # nn.MaxPool2d(kernel_size=?, stride=?)\n",
    "        # nn.Dense(in_channels=?, out_channels=?, weight_init=Normal(0.02))\n",
    "\n",
    "        self.conv1 = nn.Conv2d(num_channel, 6, 5, pad_mode='valid')\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5, pad_mode='valid')\n",
    "        self.relu = nn.ReLU()\n",
    "        self.max_pool2d = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.dense1 = nn.Dense(16*5*5, 120)\n",
    "        self.dense2 = nn.Dense(120, 84)\n",
    "        self.dense3 = nn.Dense(84, num_class)\n",
    "        self.flatten = nn.Flatten()\n",
    "\n",
    "    def construct(self, x):\n",
    "        # 练习三：书写正向逻辑\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.max_pool2d(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.max_pool2d(x)\n",
    "        #print(x.shape)\n",
    "        x = self.flatten(x)\n",
    "        x = self.dense1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dense2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dense3(x)\n",
    "        return x\n",
    "\n",
    "# 练习三：模型实例化，注意这里的num_channel应该是在练习二中打印出的channel数值\n",
    "model = LeNet5(num_class=10, num_channel=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 定义损失函数和优化器\n",
    "\n",
    "要训练神经网络模型，需要定义损失函数和优化器函数。\n",
    "\n",
    "- 损失函数这里使用交叉熵损失函数`CrossEntropyLoss`。\n",
    "- 优化器这里使用`Momentum`。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-04T06:43:30.952190Z",
     "start_time": "2022-01-04T06:43:30.525149Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Instantiate loss function and optimizer\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = nn.Momentum(model.trainable_params(), learning_rate=0.01, momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练及保存模型\n",
    "\n",
    "### Model基本介绍\n",
    "\n",
    "[Model](https://www.mindspore.cn/docs/en/r1.10/api_python/mindspore/mindspore.Model.html#mindspore.Model)是MindSpore提供的高阶API，可以进行模型训练、评估和推理。其接口的常用参数如下：\n",
    "\n",
    "- `network`：用于训练或推理的神经网络。\n",
    "- `loss_fn`：所使用的损失函数。\n",
    "- `optimizer`：所使用的优化器。\n",
    "- `metrics`：用于模型评估的评价函数。\n",
    "- `eval_network`：模型评估所使用的网络，未定义情况下，`Model`会使用`network`和`loss_fn`进行封装。\n",
    "\n",
    "`Model`提供了以下接口用于模型训练、评估和推理：\n",
    "\n",
    "- `fit`：边训练边评估模型。\n",
    "- `train`：用于在训练集上进行模型训练。\n",
    "- `eval`：用于在验证集上进行模型评估。\n",
    "- `predict`：用于对输入的一组数据进行推理，输出预测结果。\n",
    "\n",
    "### 使用Model接口\n",
    "\n",
    "对于简单场景的神经网络，可以在定义`Model`时指定前向网络`network`、损失函数`loss_fn`、优化器`optimizer`和评价函数`metrics`。\n",
    "\n",
    "### 定义Callback\n",
    "\n",
    "在深度学习训练中，为及时掌握网络模型的训练状态、实时观察网络模型各参数的变化情况和实现训练过程中用户自定义的一次额操作，MindSpore提供了回调机制（Callback）来实现上述功能。\n",
    "\n",
    "Callback回调机制一般用在网络模型训练过程`Model.train`中，MindSpore的`Model`会按照Callback列表`callbacks`顺序执行回调函数。\n",
    "\n",
    "在本次任务中，开始训练之前，MindSpore需要提前声明网络模型在训练过程中是否需要保存中间过程和结果，因此使用`ModelCheckpoint`接口用于保存网络模型和参数，以便进行后续的Fine-tuning（微调）操作。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-04T06:43:31.009605Z",
     "start_time": "2022-01-04T06:43:30.954322Z"
    }
   },
   "outputs": [],
   "source": [
    "steps_per_epoch = train_dataset.get_dataset_size()\n",
    "\n",
    "config = CheckpointConfig(save_checkpoint_steps=steps_per_epoch)\n",
    "ckpt_callback = ModelCheckpoint(prefix=\"cifar10\", directory=\"./checkpoint\", config=config)\n",
    "\n",
    "loss_callback = LossMonitor(steps_per_epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***练习四：通过MindSpore提供的`model.fit`接口进行网络训练，并通过Callback保存`ckpt`，监控`loss`变化***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-04T06:43:31.042129Z",
     "start_time": "2022-01-04T06:43:31.011659Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1 step: 781, loss is 1.652235746383667\n",
      "Eval result: epoch 1, metrics: {'accuracy': 0.4221754807692308}\n",
      "epoch: 2 step: 781, loss is 1.5244983434677124\n",
      "Eval result: epoch 2, metrics: {'accuracy': 0.495693108974359}\n",
      "epoch: 3 step: 781, loss is 1.2929081916809082\n",
      "Eval result: epoch 3, metrics: {'accuracy': 0.5512820512820513}\n",
      "epoch: 4 step: 781, loss is 1.3503402471542358\n",
      "Eval result: epoch 4, metrics: {'accuracy': 0.5614983974358975}\n",
      "epoch: 5 step: 781, loss is 1.119059681892395\n",
      "Eval result: epoch 5, metrics: {'accuracy': 0.5739182692307693}\n",
      "epoch: 6 step: 781, loss is 1.2889869213104248\n",
      "Eval result: epoch 6, metrics: {'accuracy': 0.5950520833333334}\n",
      "epoch: 7 step: 781, loss is 1.3357627391815186\n",
      "Eval result: epoch 7, metrics: {'accuracy': 0.5958533653846154}\n",
      "epoch: 8 step: 781, loss is 1.2336413860321045\n",
      "Eval result: epoch 8, metrics: {'accuracy': 0.6001602564102564}\n",
      "epoch: 9 step: 781, loss is 1.24985671043396\n",
      "Eval result: epoch 9, metrics: {'accuracy': 0.6185897435897436}\n",
      "epoch: 10 step: 781, loss is 1.0906260013580322\n",
      "Eval result: epoch 10, metrics: {'accuracy': 0.6063701923076923}\n"
     ]
    }
   ],
   "source": [
    "train_dataset = datapipe(os.path.join(path, 'cifar-10-batches-bin'), 'train', 32, 64)\n",
    "test_dataset = datapipe(os.path.join(path, 'cifar-10-batches-bin'), 'test', 32, 64)\n",
    "\n",
    "epochs = 10\n",
    "\n",
    "# 练习四：实例化Model，并通过model.fit进行网络训练\n",
    "trainer = Model(model, loss_fn=loss_fn,optimizer=optimizer, metrics={'accuracy'})\n",
    "trainer.fit(epochs, train_dataset, test_dataset, callbacks=[ckpt_callback, loss_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "训练过程中会打印loss值，loss值会波动，但总体来说loss值会逐步减小，精度逐步提高。每个人运行的loss值有一定随机性，不一定完全相同。\n",
    "\n",
    "通过模型运行测试数据集得到的结果，验证模型的泛化能力：\n",
    "\n",
    "1. 使用`model.eval`接口读入测试数据集。\n",
    "2. 使用保存后的模型参数进行推理。\n",
    "\n",
    "***练习五：通过`model.eval`打印训练好的模型在测试集上的准确率***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.6065705128205128}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 练习五：使用model.eval进行模型评估\n",
    "acc = trainer.eval(test_dataset)\n",
    "acc"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ms1.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
